{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/TranThiDieuHien/Cac-thuat-toan-toi-uu/blob/main/MatrixFactorize_Proximal_Gradient_Descent_Lite.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Cài đặt thư viện"
      ],
      "metadata": {
        "id": "8iE6ZHmvlKZj"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GQUpaCuV7gMH",
        "outputId": "44be0810-bd35-4391-c153-3b4a00044d13"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.7/98.7 MB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.5/62.5 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.8/16.8 MB\u001b[0m \u001b[31m66.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m324.4/324.4 kB\u001b[0m \u001b[31m31.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m532.9/532.9 kB\u001b[0m \u001b[31m34.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m357.5/357.5 kB\u001b[0m \u001b[31m32.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m381.9/381.9 kB\u001b[0m \u001b[31m32.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m102.7/102.7 kB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m679.5/679.5 kB\u001b[0m \u001b[31m51.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m296.5/296.5 kB\u001b[0m \u001b[31m27.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.7/4.7 MB\u001b[0m \u001b[31m54.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m62.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for tabml (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for GPUtil (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for htmlmin (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "lida 0.0.10 requires fastapi, which is not installed.\n",
            "lida 0.0.10 requires kaleido, which is not installed.\n",
            "lida 0.0.10 requires python-multipart, which is not installed.\n",
            "lida 0.0.10 requires uvicorn, which is not installed.\n",
            "llmx 0.0.15a0 requires cohere, which is not installed.\n",
            "llmx 0.0.15a0 requires openai, which is not installed.\n",
            "llmx 0.0.15a0 requires tiktoken, which is not installed.\n",
            "orbax-checkpoint 0.4.2 requires jax>=0.4.9, but you have jax 0.3.25 which is incompatible.\n",
            "plotnine 0.12.4 requires numpy>=1.23.0, but you have numpy 1.22.4 which is incompatible.\n",
            "tensorflow-probability 0.22.0 requires typing-extensions<4.6.0, but you have typing-extensions 4.8.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "!pip install tabml -q\n",
        "import tabml.datasets\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "df_dict = tabml.datasets.download_movielen_1m()\n",
        "users, movies, ratings = df_dict[\"users\"], df_dict[\"movies\"], df_dict[\"ratings\"]\n",
        "\n",
        "train_ratings, validation_ratings = train_test_split(\n",
        "    ratings, test_size=0.1, random_state=42\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Mô tả tập dữ liệu"
      ],
      "metadata": {
        "id": "o_v2vV7uld_E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "users_in_validation = validation_ratings[\"UserID\"].unique()\n",
        "all_users = users[\"UserID\"].unique()\n",
        "\n",
        "print(f\"There are {len(users_in_validation)} users in validation set.\")\n",
        "print(f\"Total number of users: {len(all_users)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5_LEBnsE8VA2",
        "outputId": "78f4aea7-d887-4354-ce21-d7e7a37a3cf0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are 5970 users in validation set.\n",
            "Total number of users: 6040\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "movie_index_by_id = {id: i for i, id in enumerate(movies[\"MovieID\"])}"
      ],
      "metadata": {
        "id": "qftXfz-a8aAr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "genres = [\n",
        "    \"Action\",\n",
        "    \"Adventure\",\n",
        "    \"Animation\",\n",
        "    \"Children's\",\n",
        "    \"Comedy\",\n",
        "    \"Crime\",\n",
        "    \"Documentary\",\n",
        "    \"Drama\",\n",
        "    \"Fantasy\",\n",
        "    \"Film-Noir\",\n",
        "    \"Horror\",\n",
        "    \"Musical\",\n",
        "    \"Mystery\",\n",
        "    \"Romance\",\n",
        "    \"Sci-Fi\",\n",
        "    \"Thriller\",\n",
        "    \"War\",\n",
        "    \"Western\",\n",
        "]\n",
        "genre_index_by_name = {name:i for i, name in enumerate(genres)}\n",
        "\n",
        "import numpy as np\n",
        "# build binary array for movie genres\n",
        "movie_features = np.zeros((len(movies), len(genres)))\n",
        "for i, movie_genres in enumerate(movies[\"Genres\"]):\n",
        "    for genre in movie_genres.split(\"|\"):\n",
        "        genre_index = genre_index_by_name[genre]\n",
        "        movie_features[i, genre_index] = 1"
      ],
      "metadata": {
        "id": "VqulxknM8aDj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. Xây dựng mô hình đề xuất film dựa trên Proximal Gradient Descent(PG Method)"
      ],
      "metadata": {
        "id": "ahkmo9c1UUG_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "import pandas as pd\n",
        "import tabml.datasets\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "class PGRegressor:\n",
        "    def __init__(self, learning_rate=0.1, regularization_term=0.1, max_iter=1000, tol=1e-3):\n",
        "        self.learning_rate = learning_rate\n",
        "        self.regularization_term = regularization_term\n",
        "        self.max_iter = max_iter\n",
        "        self.tol = tol\n",
        "        self.coef_ = None\n",
        "        self.intercept_ = None\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        X = np.c_[np.ones(X.shape[0]), X]  # Add bias term\n",
        "        num_samples, num_features = X.shape\n",
        "\n",
        "        self.coef_ = np.zeros(num_features)\n",
        "        for _ in range(self.max_iter):\n",
        "            gradients = compute_gradients(X, y, self.coef_)\n",
        "            proximal_term = self.learning_rate * self.regularization_term * np.sign(self.coef_)\n",
        "            self.coef_ = proximal_operator(self.coef_ - self.learning_rate * gradients, proximal_term)\n",
        "\n",
        "            if np.linalg.norm(gradients) < self.tol:\n",
        "                break\n",
        "\n",
        "        self.intercept_ = self.coef_[0]\n",
        "        self.coef_ = self.coef_[1:]\n",
        "\n",
        "    def predict(self, X):\n",
        "        return X @ self.coef_ + self.intercept_\n",
        "\n",
        "def compute_gradients(X, y, theta):\n",
        "    m = len(y)\n",
        "    predictions = X.dot(theta)\n",
        "    errors = predictions - y\n",
        "    gradients = (1/m) * X.T.dot(errors)\n",
        "    return gradients\n",
        "\n",
        "def proximal_operator(u, proximal_term):\n",
        "    return np.sign(u) * np.maximum(0, np.abs(u) - proximal_term)\n",
        "\n",
        "# Your existing code\n",
        "\n",
        "df_dict = tabml.datasets.download_movielen_1m()\n",
        "users, movies, ratings = df_dict[\"users\"], df_dict[\"movies\"], df_dict[\"ratings\"]\n",
        "\n",
        "train_ratings, validation_ratings = train_test_split(\n",
        "    ratings, test_size=0.1, random_state=42\n",
        ")\n",
        "\n",
        "users_in_validation = validation_ratings[\"UserID\"].unique()\n",
        "all_users = users[\"UserID\"].unique()\n",
        "\n",
        "print(f\"There are {len(users_in_validation)} users in the validation set.\")\n",
        "print(f\"Total number of users: {len(all_users)}\")\n",
        "\n",
        "movie_index_by_id = {id: i for i, id in enumerate(movies[\"MovieID\"])}\n",
        "\n",
        "genres = [\n",
        "    \"Action\", \"Adventure\", \"Animation\", \"Children's\", \"Comedy\", \"Crime\",\n",
        "    \"Documentary\", \"Drama\", \"Fantasy\", \"Film-Noir\", \"Horror\", \"Musical\",\n",
        "    \"Mystery\", \"Romance\", \"Sci-Fi\", \"Thriller\", \"War\", \"Western\"\n",
        "]\n",
        "genre_index_by_name = {name: i for i, name in enumerate(genres)}\n",
        "\n",
        "movie_features = np.zeros((len(movies), len(genres)))\n",
        "for i, movie_genres in enumerate(movies[\"Genres\"]):\n",
        "    for genre in movie_genres.split(\"|\"):\n",
        "        genre_index = genre_index_by_name[genre]\n",
        "        movie_features[i, genre_index] = 1\n",
        "\n",
        "def train_user_model(user_id):\n",
        "    user_ratings = train_ratings[train_ratings[\"UserID\"] == user_id]\n",
        "    movie_indexes = [movie_index_by_id[movie_id] for movie_id in user_ratings[\"MovieID\"]]\n",
        "    train_data = movie_features[movie_indexes]\n",
        "    train_label = user_ratings[\"Rating\"]\n",
        "    model = PGRegressor(learning_rate=0.1, regularization_term=0.1, max_iter=1000, tol=1e-3)\n",
        "    model.fit(train_data, train_label)\n",
        "    return model\n",
        "\n",
        "user_model_dict = {}\n",
        "for user_id in users[\"UserID\"].unique():\n",
        "    user_model_dict[user_id] = train_user_model(user_id)\n",
        "\n",
        "def predict(user_id, movie_id):\n",
        "    movie_feature = movie_features[movie_index_by_id[movie_id]].reshape((1, -1))\n",
        "    pred = user_model_dict[user_id].predict(movie_feature)\n",
        "    return min(max(pred, 1), 5)\n",
        "\n",
        "print(f\"RMSE train: {eval_rmse(train_ratings)}\")\n",
        "print(f\"RMSE validation: {eval_rmse(validation_ratings)}\")\n",
        "\n",
        "end_time = time.time()\n",
        "execution_time = end_time - start_time\n",
        "\n",
        "print(f\"Thời gian chạy của chương trình là: {execution_time} giây.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xFuGK3lPUW2j",
        "outputId": "55a627e5-2598-47c7-a5b4-1388a225341b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are 5970 users in the validation set.\n",
            "Total number of users: 6040\n",
            "RMSE train: 1.4367441863247723\n",
            "RMSE validation: 1.5659809079196119\n",
            "Thời gian chạy của chương trình là: 2892.0366683006287 giây.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4. Thực hiện kiểm tra mô hình với id người dùng 160(user_id = 160)"
      ],
      "metadata": {
        "id": "yL2wEN2Sl-rC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "user_id = 160\n",
        "for genre, coef in zip(genres, user_model_dict[user_id].coef_):\n",
        "    print(\"{:15s}: {:.3f}\".format(genre, coef))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g0Ct7YYW8aYK",
        "outputId": "1691d607-ca59-4a60-bfa5-f8fc7811edc3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Action         : -0.531\n",
            "Adventure      : 0.989\n",
            "Animation      : 0.124\n",
            "Children's     : -0.219\n",
            "Comedy         : -0.969\n",
            "Crime          : 0.438\n",
            "Documentary    : 0.000\n",
            "Drama          : 0.026\n",
            "Fantasy        : -0.343\n",
            "Film-Noir      : 0.000\n",
            "Horror         : 0.018\n",
            "Musical        : 0.124\n",
            "Mystery        : 0.000\n",
            "Romance        : 1.001\n",
            "Sci-Fi         : -0.437\n",
            "Thriller       : -0.988\n",
            "War            : -1.993\n",
            "Western        : 0.000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "Wmp3jWAimJH5"
      }
    }
  ]
}